import streamlit as st
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import cv2
import tempfile

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (h5)
@st.cache_resource
def load_ai_model():
    model = load_model("fabric_defect_model.h5")  # ØºÙŠÙ‘Ø± Ø§Ù„Ø§Ø³Ù… Ù„Ùˆ Ù…Ø®ØªÙ„Ù
    return model

model = load_ai_model()

# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
st.set_page_config(page_title="Fabric Defect Detection", page_icon="ğŸ§µ", layout="wide")

st.title("ğŸ§µ ØªØ·Ø¨ÙŠÙ‚ Ù…Ø¨Ù‡Ø± Ù„ÙƒØ´Ù Ø¹ÙŠÙˆØ¨ Ø§Ù„Ø£Ù‚Ù…Ø´Ø© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ")
st.markdown("### Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© Ù„Ù„Ù‚Ù…Ø§Ø´ØŒ ÙˆØ§Ù„Ù†Ø¸Ø§Ù… Ù‡ÙŠØ­Ù„Ù„Ù‡Ø§ ÙˆÙŠÙ‚ÙˆÙ„Ùƒ Ø§Ù„Ù†ØªÙŠØ¬Ø©")

# Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±Ø©
uploaded_file = st.file_uploader("Ø§Ø®ØªØ§Ø± ØµÙˆØ±Ø©", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¤Ù‚ØªÙ‹Ø§
    with tempfile.NamedTemporaryFile(delete=False) as tmp:
        tmp.write(uploaded_file.read())
        img_path = tmp.name

    # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
    st.image(img_path, caption="ğŸ“· Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©", use_column_width=True)

    # ØªØ¬Ù‡ÙŠØ² Ø§Ù„ØµÙˆØ±Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„
    img = image.load_img(img_path, target_size=(224, 224))  # ØºÙŠÙ‘Ø± Ø§Ù„Ø­Ø¬Ù… Ù„Ùˆ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù…Ø®ØªÙ„Ù
    img_array = image.img_to_array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)

    # Ø§Ù„ØªÙ†Ø¨Ø¤
    prediction = model.predict(img_array)
    score = float(prediction[0][0])  # Ù„Ùˆ Binary Classification
    label = "âœ… Ø³Ù„ÙŠÙ…" if score < 0.5 else "âŒ Ù…Ø¹ÙŠØ¨"

    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø©
    st.subheader("ğŸ” Ø§Ù„Ù†ØªÙŠØ¬Ø©")
    st.write(f"**{label}** (Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø©: {round(score*100, 2)}%)")

    # ğŸ”¥ Ø¥Ø¶Ø§ÙØ© Heatmap (Grad-CAM) Ù„Ù„Ø¥Ø¨Ù‡Ø§Ø±
    last_conv_layer = model.get_layer(model.layers[-3].name)  # Ø¢Ø®Ø± Ø·Ø¨Ù‚Ø© Convolution
    grad_model = tf.keras.models.Model([model.inputs], [last_conv_layer.output, model.output])

    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img_array)
        loss = predictions[:, 0]

    grads = tape.gradient(loss, conv_outputs)[0]
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    conv_outputs = conv_outputs[0]

    heatmap = np.mean(conv_outputs * pooled_grads, axis=-1)
    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)
    heatmap = cv2.resize(heatmap, (img.size[0], img.size[1]))

    img_original = cv2.imread(img_path)
    heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)
    superimposed_img = cv2.addWeighted(img_original, 0.6, heatmap_colored, 0.4, 0)

    st.subheader("ğŸŒ¡ï¸ Ù…Ù†Ø·Ù‚Ø© ØªØ±ÙƒÙŠØ² Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ (Heatmap)")
    st.image(superimposed_img, channels="BGR", use_column_width=True)

    # Dashboard Ø¨Ø³ÙŠØ·Ø©
    st.subheader("ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©")
    st.metric(label="Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ÙØ­ÙˆØµØ©", value="1")
    st.metric(label="Ù†Ø³Ø¨Ø© Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø¹ÙŠÙˆØ¨", value=f"{round(score*100,2)}%")
